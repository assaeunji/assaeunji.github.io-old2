---
layout: post
title: "인과 관계 분석 시리즈 (4): 머신러닝을 이용한 인과관계 추론 (feat. Metalearners)"
date: 2020-07-05
categories: [Machine Learning]
tag: [causal-inference, supervised-learning, potential-outcome, probability, propensity-score,causalml, python]
comments: true
---

* 이번 포스팅에서는 Künzel et al. (2019) 의 Metalearners for estimating heterogeneous treatment effects using machine learning 라는 논문을 읽으면서 내용을 정리했습니다.
* 이 논문은 인과관계 추론 중 Potential outcome에 기반하고, CATE<sup>Conditional Average Treatment Effect, 조건 평균 처리 효과</sup>을 머신러닝 방법으로 추정하는건데, 이를  **신선하게** Metalearner 라는 방법으로 접근했습니다.
* 인과관계 추론에 대한 기본 지식이 필요하시다면 [Introduction to Bayesian Causal Inference](https://assaeunji.github.io/bayesian/2020-04-10-causal/){:target="_blank"}을 참조해주세요 :D


---
## Framework and Definitions

이 논문을 이해하려면 **Potential Outcome Framework**를 잘 이해하는 게 중요합니다.

### Notation

먼저, $N$개의 훈련 데이터가 있을 때 $i$번째 데이터를 $(Y_i(0), Y_i(1), X_i, W_i)$로 표현할 수 있습니다. 여기서
* $W_i$: $W_i \in \{0,1\}$로 처리 여부로 0이면 처리를 받지 않은 것이고 1이면 처리를 받은 것을 의미합니다.
* $X_i$: $X_i \in \mathbb{R}^d$로, 처리 여부 $W_i$와 결과에 모두 영향을 주는 $d$개의 교란변수 (confounder)를 의미합니다.  
* $Y_i(0), Y_i(1)$: 처리를 받지 않았을 때와 받았을 때의 가상의 결과 (potential outcome)를 의미합니다. 
    예를 들어, $i$번째 개체가 처리를 받았다면 ($W_i = 1$), $Y_i(1)$의 값은 실제로 갖게 되지만 $Y_i(0)$의 값은 알 수 없고, 처리를 받지 않았다면 $Y_i(1)$의 값을 알 수 없기 때문에 
    **가상의 결과**라는 명칭이 쓰이게 되었습니다.


### ATE

이 notation을 가지고 ATE<sup>Average Treatment Effect, 평균 처리 효과</sup>를 정의하면 다음과 같습니다.

$$
\text{ATE}:= \mathbb{E}[Y(1) - Y(0)]
$$

또한 다음과 같이 처리가 없을 때의 반응 함수 $\mu_0(x)$와 처리가 있을 때의 반응 함수 $\mu_1(x)$ 를 

$$
\mu_0 (x) := \mathbb{E}[Y(0)\vert X=x] \quad\text{and}\quad \mu_1(x) := \mathbb{E}[Y(1)\vert X=x]
$$

로 정의하면 데이터 $(Y_i(0), Y_i(1), X_i, W_i)$의 관계를 표현할 수 있습니다.

$$
\begin{aligned}
X &\sim \Lambda \\
W &\sim \text{Bernoulli} (e(X))\\
Y(0) &= \mu_0 (X) + \varepsilon(0)\\
Y(1) &= \mu_1 (X) + \varepsilon(1)
\end{aligned}
$$

여기서 $\Lambda$는 $X$의 주변 분포, $\varepsilon(0)$과 $\varepsilon(1)$은 $X$와 $W$에 독립이고 평균이 0인 확률 변수입니다. 
또한 $e(X)$는 성향점수 (propensity score)입니다. 성향 점수는 처리에 영향을 주는 교란변수을 찾아 처리가 1일 확률 $P(W=1\vert X)$를 추정한 것을 의미합니다.
성향 점수에 대한 자세한 설명은 [이 포스팅](https://assaeunji.github.io/statistics/2020-06-21-matching/){:target="_blank"}을 참고하세요!


앞서 말씀드렸듯이 관측 환경의 데이터는 potential outcome 두 개를 동시에 관측할 수 없습니다. 대신에 

$$
\mathcal{D} = (Y_i, X_i, W_i),\ i=1,\cdots,N
$$

만 관측하게 되죠. 참고로 처리를 받은 개체와 처리를 받지 않은 개체가 최소 1명 이상은 되어야 합니다. 
또한 $(X_i^a, Y_i^a), a = \{0,1\}$으로 표기하면 처리에 따른 데이터를 의미합니다. 즉 $(X_i^0, Y_i^0)$은 처리를 받지 않은 $i$번째 개체, $(X_i^1, Y_i^1)$은 처리를 받은 $i$번째 개체의 데이터입니다.

### ITE

이제 $x_i$의 공변량들(covariates)을 가진 $i$번째 개체에 대해서 인과 효과를 구하려면 ITE<sup>Individual Treatment Effect, 개인 처리 효과</sup>를 구해야 합니다. ITE는 다음과 같이 정의가 됩니다.

$$
D_i:= Y_i(1) - Y_i(0)
$$

그러나, 관측 데이터에서는 $Y_i(0)$이나 $Y_i(1)$ 하나만 관측되기 때문에 ITE를 구하는 건 불가능합니다. 대신에 CATE는 가능하죠.

### CATE

CATE는 Condional Average Treatment Effect의 준말로 교란 변수를 조건으로 했을 때 평균 인과 효과를 의미합니다.

$$
\tau(x) := \mathbb{E}[D\vert X=x] = \mathbb{E}[Y(1) - Y(0)\vert X=x]
$$

### CATE를 위한 가정

CATE를 잘 추정하려면 가정 2개를 해야 합니다. 

> 가정 1 (Unconfoundedness) : $X$를 조건으로 했을 때 potential outcome은 처리와 독립이여야 합니다. 이 가정이 위반하는 경우는 알려지지 않은 교란 변수가 더 존재할 때이기 때문에, 가정을 만족시키기 위해선 최대한 알려진 교란 변수를 많이 찾아야 함을 의미합니다. 

$$
Y_i(0),Y_i(1) \perp \!\!\! \perp W\vert X
$$

> 가정 2 (Positivity / Overlap): $X$의  support안에서 CATE가 identifiable해야 합니다. 즉 성향 점수 (propensity score)가 0이 되거나 1이 되서는 안됩니다.

$$ 
0<e(x) = P(W)=1\vert X)<1
$$

---
## Metalearner

![](../../images/causalml-metamon.jpg)
[이미지 출처](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.coupang.com%2Fnp%2Fsearch%3Fq%3D%25EB%25A9%2594%25ED%2583%2580%25EB%25AA%25BD%25EC%259D%25B8%25ED%2598%2595%26channel%3Drelate&psig=AOvVaw1IItd69Wp1BmtZrpcBqW7B&ust=1593922739244000&source=images&cd=vfe&ved=0CAkQjhxqFwoTCNDhhYjfsuoCFQAAAAAdAAAAABAI){:target="_blank"}
{:.figure}

자. 이제 CATE를 추정하기 위한 Metalearner에 대해 알아봅시다. 위의 그림의 메타몽이 피카츄, 파이리, 이상해씨가 되듯이 Metalearner의 "meta"는 CATE를 추정하기 위한 **base 알고리즘**이 랜덤포레스트나 BART (Bayesian Additive Regression Tree)처럼 여러 형태를 가질 수 있음을 의미합니다.

기존의 CATE 추정을 위한 방법론은 S-learner<sup>Single learner, 단일 학습기</sup>와 T-learner<sup>Two learners, 이중 학습기</sup>였는데요. 여기서는 Metalearner로 **X-learner**라는 명칭을 사용합니다. 하나 하나씩 알아보겠습니다.

---
### T-learner

![](../../images/causalml-tlearner.png)

T-learner는 
1. 처리를 받지 않은 개체와 받은 개체를 따로 분리해 각각 선형 회귀든 나무모형이든 머신러닝 모형을 통해 학습한 후 
2. 이들의 차이로 CATE를 추정합니다.

여기서 $(X^0, Y^0)$은 처리를 받지 않은 개체들의 공변량들과 반응값을 의미하고 $(X^1, Y^1)$은 처리를 받은 개체들의 공변량과 반응값을 의미합니다.
이렇게 추정된 $\widehat{\mu}_0$과 $\widehat{\mu}_1$은 각각 $\mu_0(x) = \mathbb{E} [Y(0)\vert X=x]$와 $\mu_1(x) = \mathbb{E}[Y(1)\vert X=x]$의 추정값입니다.

따라서 T-learner를 이용힌 CATE 추정은 다음과 같습니다.

$$
\widehat{\tau}_T(x) = \widehat{\mu}_1 (x) - \widehat{\mu}_0 (x)
$$


---
### S-learner

![](../../images/causalml-slearner.png)

S-learner는
1. $Y$를 반응변수로 두고 교란변수와 처리를 **같이** 설명변수로 두어 마찬가지로 회귀 모형, 나무 모형과 같은 머신러닝 모형을 이용해 학습한 후,
2. $W=1$일 때의 추정값에서 $W=0$일 때의 추정값을 빼서 CATE를 추정합니다.

즉, 여기서 추정된 $\widehat{\mu}$는 $\mu(x,w) = \mathbb{E}[Y^{\text{obs}} \vert X=x, W=w]$를 추정한 것입니다. 이후 추정된 CATE는 추정된 $\widehat{\mu}$에 $w=1$을 대입한 $\widehat{\mu}(x,1)$에서 $w=0$을 대입한 $\widehat{\mu}(x,0)$를 뺀 값입니다.

$$
\widehat{\tau}_S(x) = \widehat{\mu}(x,1) - \widehat{\mu}(x,0)
$$

---
### X-learner

![](../../images/causalml-xlearner.png)

마지막으로 X-learner는
1. T-learner처럼 처리를 받은 개체와 처리를 받지 않은 개체들끼리 나누어 반응 함수 (response function)을 추정해 $\widehat{\mu}_0$, $\widehat{\mu}_1$를 계산하고
2. 각 개체에 대해서 처리 효과를 **impute**합니다. 예를 들어 처리를 받은 개체는 $Y_i^1$은 존재하지만, $Y_i^0$은 존재하지 않기 때문에 $Y_i^0$를 $\widehat{\mu}_0(x)$에 $X_i^1$를 대입한 $\widehat{\mu}_0(X_i^1)$로 **대체**한 후에, imputed 개별 처리 효과인 $\tilde{D}_i^1$를 구할 수 있습니다. 마찬가지로 처리를 받지 않은 개체는 $Y_i^0$은 존재하지만 $Y_i^1$은 존재하지 않기 때문에 $Y_i^1$을 $\widehat{\mu}_1(X_i^0)$으로 대체하여 $\tilde{D}_i^0$을 구합니다.  
3. 이제 $\tilde{D}_i^0$를 처리를 받지 않은 $X_i^0$로 모델링하고 $\tilde{D}_i^1$를 처리를 받은 $X_i^1$로 모델링해 $\widehat{\tau}_0(x) = \mathbb{E}[\tilde{D}_i^0 \vert X^0=x]$와 $\widehat{\tau}_1(x) =\mathbb{E}[\tilde{D}_i^1 \vert X^1=x]$를 구합니다.
4. 마지막으로 CATE를 다음과 같이 $\widehat{\tau}_0(x)$와 $\widehat{\tau}_1(x)$의 가중 평균으로 추정합니다.
   $$
   \widehat{\tau}(x) = g(x) \widehat{\tau}_0(x) + (1- g(x)) \widehat{\tau}_1(x)
   $$ 

여기서 $g$의 좋은 추정값은 성향 점수 (propensity score)의 추정값인 $\widehat{e}(x)$입니다. 다만, 만약 처리를 받은 개체가 받지 않은 개체보다 매우 많다면 $g=1$, 적다면 $g=0$을 선택할 수 있습니다.

**그렇다면 X-learner이 S-learner나 T-learner에 비해 갖는 장점은 무엇일까요?**

이 글의 저자는 X-learner의 장점은 
1. unbalanced design, 즉 처리 받은 개체와 받지 않은 개체의 수가 크게 차이가 날 때
2. CATE 함수 모양에 따른 유연한 적합

이라 말하고 있습니다. 

실제로 이 X-learner가 다른 학습기에 비해 성능이 우수한 지에 대한 내용은 **다음에** 살펴보겠습니다.



<!-- 
실제로 얼마나 잘 하는지 시뮬레이션을 통해 살펴봅시다.

---
## Simulation

시뮬레이션을 위해 Python의 `causalml`패키지를 이용합니다.
먼저, `causalml` 패키지를 쓰려면 Microsoft Visual C++ 14.0을 설치해주어야 합니다. Microsoft Visual C++ 14.0는 https://visualstudio.microsoft.com/ko/downloads/에서 `Tools for Visual Studio 2019` > `Visual Studio 2019용 Build Tools`클릭해 설치할 수 있습니다. 그럼 이런 installer 창이 뜨는데 완료될 때까지 기다립니다. 약 4GB 용량을 차지하네요...!

![](../../images/causalml-vsinstaller.png) -->





---
## References
* Künzel, Sören R., et al. "Metalearners for estimating heterogeneous treatment effects using machine learning." Proceedings of the national academy of sciences 116.10 (2019): 4156-4165. [`[link]`](https://www.pnas.org/content/116/10/4156){:target="_blank"}