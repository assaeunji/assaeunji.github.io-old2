---
layout: post
title: "배깅 (Bagging)과 부스팅 (Boosting)의 원리"
date: 2020-08-06
categories: [ML]
tag: [supervised-learning, bagging, boosting, tree algorithm]
comments: true
photos:
    - "../../images/tree-titleimage.jpg"

---

* 자주 & 편히 쓰는 배깅과 부스팅 기반의 나무 알고리즘, 그 원리에 대해 자세히 설명하실 수 있으신가요? 
이는 데이터 분석 직군 면접에서 묻는 단골 소재이기도 한데요 (실제 면접 본 곳의 100%가 랜덤포레스트의 원리에 대해 설명하라 했었습니다 (...)). 이에 대한 개념을 차근차근 알아보고자 포스팅을 쓰게 되었습니다.


---
## Introduction

배깅과 부스팅을 알아보기 전에 **앙상블 학습**에 대한 개념을 알아야 합니다. **앙상블 학습** (Ensemble Learning)이란 여러 개의 분류기 (Classifier)를 생성하고 그 예측을 결합해 단일 분류기보다 정확한 최종적 예측을 도출해내는 기법을 의미합니다.

앙상블 학습의 유형은 크게 세 가지입니다 (그 외에도 스태킹을 포함한 다양한 앙상블 방법이 있다고 합니다).
* 보팅 (Voting)
* 배깅 (Bagging)
* 부스팅 (Boosting)

나무 알고리즘 중 랜덤 포레스트 (Random Forest)는 **배깅**, 나머지 Gradient Boosting, Light GBM, XGBoost는 모두 **부스팅**을 이용한 방법입니다.
그렇다면 배깅, 부스팅은 어떤 방법을 의미할까요?

----
## 배깅 (Bagging)

**배깅 (Bagging)**은 Bootstrap + Aggregating의 합성어로, "부트스트랩 샘플을 합친다!"라고 한 마디로 말씀드릴 수 있습니다. **부트스트랩 (Bootstrap)**이란 원래 통계학에서 표본 분포 (Sampling Distribution)을 구하기 위해 데이터를 여러 번 복원 추출 (resampling)하는 것을 의미합니다.

평균이 $\overline{X}$이고, 분산이 $\sigma^2/n$인 서로 독립인 $n$개의 데이터 $X_1,\ldots X_n$가 있을 때 이를 하나의 표본 (samples)이라 부릅니다. 그리고 보통 모집단 (population)의 모평균과 모분산을 추정하기 위해 표본 분포를 구합니다.
근데 표본 분포를 구하려면 또 $n$개의 표본들을 여러 개 구해야 하는데 사실상 쉽지가 않은 과정이죠.

이런 한계를 극복하기 위해 나온 과정이 부트스트랩입니다. 하나의 표본을 가지고 $B$ 번 복원 추출 (resampling) 한다면 이 **부트스트랩 샘플들의 분포가 표본 분포로 근사된다**는 것이 핵심입니다. 

자, 그럼 부트스트랩 샘플들을 어떻게 추출하는 지 그림을 통해 알아봅시다.
예를 들어 1,2,3,...,0까지의 값을 가진 $n=10$개인 하나의 표본이 있을 때 이 표본으로 $B=3$개의 부트스트랩 샘플을 추출하면 다음과 같습니다.

![](../../images/tree-bootstrap.png)

오른쪽의 세 개의 부트스트랩 샘플들은 왼쪽의 데이터 개수와 동일하지만, 개별 데이터가 중복되는 특징이 있습니다. 이렇게 
* 표본 크기와 똑같이 $B$번
* 복원 추출 (with replacement)
하는 것이 부트스트랩 샘플의 특징입니다.
만약 표본 평균을 구하는 것을 목표로 한다면 $B$ 번 추출한 부트스트랩 샘플들의 평균 $B$개들의 평균으로 근사할 수 있습니다. 

즉, 위의 예에서 3개의 부트스트랩 샘플에서 나온 평균 5, 4.9, 4.6의 합을 $B=3$으로 나누어주면 표본평균을 4.83으로 근사하게 됩니다. 


이러한 철학을 나무 모형에 적용한 게 배깅이고, 배깅을 이용한 대표적인 나무 알고리즘은 랜덤 포레스트입니다. 
랜덤 포레스트가 분류기를 만드는 과정은 다음과 같습니다. 

1. $N$개의 관측치와 $M$개의 피처를 가진 데이터가 있다 할 때 $B$개의 부트스트랩 샘플을 추출합니다. 각 샘플은 중복 추출된 샘플입니다. 
    * 여기서 부트스트랩 샘플의 개수인 $B$는 `sklearn.ensemble.RandomForestClassifier`의 `n_estimators`로 조절하고 기본값은 100입니다.
    * 또한 각 부트스트랩 샘플의 크기는 `max_samples`로 조절하고, default는 데이터 개수인 $N$입니다.
2. 각 샘플에서 $M$개의 피처 중 **랜덤**하게 $d$개를 선택합니다. $d$는 보통 전채 피처 개수 $M$의 제곱근으로 주어집니다. 예를 들어 16개의 피처가 있다면 랜덤하게 4개의 피처를 선택합니다.
    * $d$는 `max_features`를 통해 조절합니다.
3. 이를 이용해 $B$개의 의사 결정 나무를 개별적으로 학습하고 최종적으로 모든 분류기가 보팅을 통해 가장 많이 나온 라벨로 예측을 합니다.

랜덤포레스트가 부트스트랩 샘플로 학습한 나무들의 예측 결과를 합치는건 알겠는데... 왜 2.의 과정처럼 랜덤하게 일부의 피처를 선택할까요?
일부의 피처를 선택하지 않고 모든 피처를 사용한다면 **과적합** (overfitting) 문제가 있기 때문입니다. 

만약 피처가 16개인데 그 중 한 4개 정도만 유의미한 (dominating) 피처이고 나머지는 예측하는 데 큰 도움이 되지 않는 피처라 가정해봅시다.
16개의 피처를 모두 이용해서 부트스트랩 샘플 개수만큼 ($B$개) 의사 결정 나무를 학습하게 되면 결국 모든 학습 결과에 들어가는 분류 기준은 피처 4개만 관련이 있을 것이고 학습한 나무들은 다 비슷비슷하니까 상관관계(correlation)은 높아집니다. 이런 비슷한 나무들로 예측 결과를 내면 하나의 나무로 예측하는 것과 마찬가지로 **높은 분산값**을 갖게 되고 과적합 문제를 야기합니다. 

따라서 랜덤 포레스트는 각 학습할 나무마다 랜덤하게 피처들을 선택해서 약한 설명력을 가지지만 상관관계는 낮은 나무들을 학습해 이들의 결과를 추합합니다. 

---
## Boosting

부스팅은 배깅과 달리
* additive training
* sequential training

라는 말이 항상 붙습니다. additive하다는 말은 여러 나무들을 합한다는 것을 의미하고, sequential이라는 의미는 여러 나무들을 동시에 학습하지 않고 한 나무가 학습된 결과를 바탕으로 더 나은 결과를 위해 다시 두 번째 나무를 학습하고, 이 두 나무들보다 나은 결과를 위해 세 번째 나무를 학습하는 등 순서대로 학습한다는 의미를 내포합니다.


![](../../images/tree-boosting.png)


이렇게 순서대로 학습해 이전 나무에서 잘못 분류한 관측치에 대해 그 다음 나무에서는 더 잘 학습하도록 하도록 합니다. 따라서, 다음 나무에서 관측치가 나타날 확률은 같지 않고, 가장 큰 오차를 보인 관측치들이 나타날 확률이 높도록 가중치를 설정합니다. 즉, 위의 배깅처럼 부트스트랩 샘플들의 각 관측치가 랜덤하게 뽑히지 않고, 오차에 기반해 관측치를 뽑는다는 점에서 차이가 있습니다.

이러한 부스팅의 원리를 사용한 알고리즘은 크게 
* AdaBoost
* Gradient Boosting Model (GBM)
* XGBoost
  
가 있는데요. 이에 대해서는 다음 포스팅에서 자세히 다루겠습니다.


----
### AdaBoost

AdaBoost는 Adaptvie Boosting의 준말입니다. AdaBoost는 분류 결과가 틀린 부분 (오류)을 개선해나가는 방향으로 업데이트됩니다. 

![](../../images/tree-adaboost1.png)

예를 들어 위의 그림처럼 나무 모형 3개를 이용한다면
1. 나무 모형 1에서 binary하게 예측합니다. 이렇게 하나의 노드만 가진 나무 모형을 **stump**<sup>나무의 그루터기, 밑동</sup>라 부릅니다.
2. 나무 모형 2는 나무 모형 1이 잘못 예측한 데이터를 더 잘 분류하도록 가중치를 크게 주어 분류합니다.
3. 나무 모형 3은 나무 모형 1, 2가 잘못 분류한 데이터를 더 잘 분류하도록 가중치를 크게 주어 분류합니다.
4. 마지막으로, 3개의 모델별로 가중치를 계산해 최종 분류 모형을 생성합니다.

![](../../images/tree-adaboost2.png)

그러면 데이터 별 가중치와 모델 별 가중치를 어떻게 계산할까요?

AdaBoost에서 최종 분류 식은 다음과 같이 $T$개의 나무 모형 예측값 $f(x)$의 가중합으로 주어집니다.

$$
F(x) = \text{sign} (\sum_{t=1}^{T} \alpha_t f_t(x))
$$

여기서 
* $f_t(x)$는 $t$ 번째 약한 학습기(weak learner)를 의미하고 
* $\alpha_t$은 $t$번째 학습 결과에 곱해지는 가중치를 의미합니다.
* 마지막에 $\text{sign}$로 $\sum_{t=1}^{T} \alpha_t f_t(x)$의 값이 양수이면 1, 음수이면 -1을 출력해 예측 결과를 냅니다.


   
만약 데이터가 $n$개의 샘플을 가졌고 $x_i \in \mathbb{R}^d$, $y_i \in \{-1,1\}$이라 할 때 AdaBoost의 가중치 계산 과정은 다음과 같습니다.

1. 모든 샘플에 똑같은 가중치를 주어 가중치를 초기화합니다.

    $$
    D_1(x_i, y_i) = \frac{1}{n},\ i=1,\ldots,n
    $$

2. $t=1,\ldots,T$번째 반복마다
   1. 데이터에 여러 개의 약한 학습기들을 적합시키고 가장 분류 오류가 낮은 것을 선택합니다. 
   
   $$
   \varepsilon_t = \frac{\text{잘못 분류한 데이터 개수}}{전체 데이터 개수} = E_{w_{t}} [1_{y \neq f(x)}]
   $$

   1. $t$번째 약한 학습기에 곱해지는 가중치 $\alpha_t$을 다음과 같이 계산합니다. 

    $$
    \alpha_t = \frac{1}{2} \ln \left( \frac{1-\varepsilon_t}{\varepsilon_t}\right)
    $$
    이 $\alpha_t$의 생김새는 다음과 같습니다.
    ![](../../images/tree-alpha.png)
    이 생김새를 바탕으로 약한 학습기의 가중치를 왜 이렇게 정했는 지 직관적으로 파악할 수 있습니다.

       * $\varepsilon \rightarrow 0$이면 $\alpha_t$는 기하적으로 커집니다. 즉 오류가 적으면 그 모형은 더 많은 가중치를 받게 됩니다.
       * 만약 $\varepsilon = 0.5$이면 $\alpha_t = 0$입니다. 50%의 정확도를 가진 분류기는 random guess (무작위로 때려 맞추는 것)과 같기 때문에 무시합니다.
       * $\varepsilon \rightarrow 1$이면 $\alpha_t$는 음수 방향으로 커집니다. 이 말인 즉슨, 50%보다 오차가 크면 분류를 잘못하고 있는 것이기 때문에 그 분류기의 결과에 **반대**되는 결과를 도출하도록 가중치를 조정하는 것입니다.
     
   2. $t$번째 훈련 데이터의 가중치를 다음과 같이 계산합니다.

   $$
   D_{t+1} (i) = \frac{D_t (i) \exp (-\alpha_t y_i f_t (x_i))}{Z_t} 
   $$

   가중치 $D(i)$를 분포로 이해하면, $D(i)$는 다음 훈련 데이터에 $i$번째 값이 포함될 확률로 이해할 수 있습니다. 분포라는 특성 상 모든 확률들을 더하면 1이되어야 하기 때문에 정규화 상수 (normalizing factor)인 $Z_t$를 나누어줍니다.

   여기에 인덱스 $i$가 붙은 이유는 각 훈련 샘플별로 이 값을 계산해줘야하기 때문입니다. 왜 가중치가 이렇게 되는 지 설명하자면 다음과 같습니다.

   ![](../../images/tree-exp.png)

   지수 함수 $\exp(x)$는 다음과 같이 $x$가 음수이면 1보다 작은 양수 값을 갖고, 양수이면 1보다 크거나 같은 값을 갖습니다. 따라서 $i$번째 샘플의 가중치는 $-\alpha_t y_i f_t (x_i)$의 부호에 따라 작은 값을 갖거나 큰 값을 갖게 됩니다. 근데 $y_i$는 $-1$이거나 $1$이고, $f_t(x_i)$는 $t$번째 나무가 분류한 $y$값을 의미하므로 결국 $y_i f_t(x_i)$도 $-1$이거나 $1$의 값을 갖습니다. 더 자세하게는 $y \neq f_t(x_i)$이면 $y_i f_t(x_i) = -1$이고, $y=f_t(x_i)$이면 $y_i f_t(x_i) = 1$이됩니다. 결과적으로, **양의 $\alpha$값을 갖고, 잘못 분류된 관측치**는 더 많은 가중치로 업데이트 됩니다.

3. 마지막으로 이들의 결과를 합산해 $F_t(x)$를 계산합니다.



https://xgboost.readthedocs.io/en/latest/tutorials/model.html

https://hyunlee103.tistory.com/25

https://mccormickml.com/2013/12/13/adaboost-tutorial/

https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c